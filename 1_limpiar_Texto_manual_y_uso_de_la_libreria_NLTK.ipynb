{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPX8kEvsRp9fWDrolYCPHrA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LuisPerdomo123/NLP-Procesamiento-de-Lenguaje-Natural/blob/main/1_limpiar_Texto_manual_y_uso_de_la_libreria_NLTK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deep Learning para Procesamiento del Lenguaje Natural\n",
        "\n",
        "# 1. Limpiar Texto manial y uso de la librería NLTK"
      ],
      "metadata": {
        "id": "plSrwXe2MmnV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Índice\n",
        "\n",
        "\n",
        "\n",
        "*   0. Contexto\n",
        "*   1. Metamorfosis de Franz Kafka\n",
        "*   2. La limpieza de texto es una tarea específica\n",
        "    *  2.1. Definición de entrada\n",
        "    *  2.2. Capas de conexión\n",
        "    *  2.3. Creación del modelo\n",
        "*   3. Tokenización manual\n",
        "    *  3.1. Cargar datos\n",
        "    *  3.2. Dividir por espacios en blanco\n",
        "    *  3.3. Seleccionar palabras\n",
        "    *  3.4. Dividir por espacios en blanco y quitar puntuación\n",
        "    *  3.5. Caso de normalización\n",
        "*   4. Tokenización y limpieza con NLTK\n",
        "    *  4.1. Instalación NLTK\n",
        "    *  4.2. Dividir en oraciones\n",
        "    *  4.3. Dividir en palabras\n",
        "    *  4.4. Filtrar la puntuación\n",
        "    *  4.5. Filtrar palabras vacías (y pipeline)\n",
        "    *  4.6. Palabras raíz\n"
      ],
      "metadata": {
        "id": "Nv5jQXIEM1Av"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. Contexto\n",
        "\n",
        "Cuando trabajmos cualquier proyecto de Machine o Deep Learning primero nos toca elaborar la fase de procesamiento de datos; en NLP igual.\n",
        "\n",
        "Primero debemos limpiar el texto, lo que significa dividirlo en palabras y manejar la puntuación y el caso. En este tutorial, descubrirá cómo puede limpiar y preparar su texto para modelarlo con aprendizaje automático. Después de completar este tutorial, sabrás:\n",
        "\n",
        "*   Cómo desarrollar nuestras propias herramientas de limpieza de texto.\n",
        "*   Cómo utilizar los métodos más sofisticados de la librería NLTK.\n",
        "*   Consideraciones al preparar texto para modelos de NLP.\n",
        "\n",
        "Este tutorial se divide en las siguientes partes:\n",
        "\n",
        "1. Libro de metamorfosis de Franz Kafka.\n",
        "2. La limpieza de texto en el libro.\n",
        "3. Tokenización manual.\n",
        "4. Tokenización y limpieza con NLTK.\n",
        "5. Consideraciones adicionales en la limpieza de texto."
      ],
      "metadata": {
        "id": "XGDDVzXFOtZG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Metamorfosis de Franz Kafka\n",
        "\n",
        "Utilizaremos el texto del libro *Metamorphosis* de Franz Kafka ya que es un libro corto, muy famoso y está disponible de forma gratuita en Project Gutenberg.\n",
        "\n",
        "El proyecto Gutenberg agrega un encabezado y un pie de página estándar a cada libro que no es parte del texto original debemos eliminarlo.\n",
        "\n",
        "El encabezado termina con el texto:\n",
        "\n",
        "******* start of this project gutenberg ebook metamorphosis *******\n",
        "\n",
        "El pie de página es todo el texto después de la línea de texto que dice:\n",
        "\n",
        "******* END OF THIS PROJECT GUTENBERG EBOOK MEAMORPHOSIS *******\n",
        "\n",
        "\n",
        "https://www.gutenberg.org/browse/languages/es\n",
        "\n",
        "\n",
        "https://www.gutenberg.org/cache/epub/5200/pg5200.txt"
      ],
      "metadata": {
        "id": "S_94QQlGR_bi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. La limpieza de texto es una tarea específica\n",
        "\n",
        "Si echamos un vistazo al libro, ¿qué notamos? Un rápido vistazo podemos ver:\n",
        "\n",
        "*   Es texto sin formato, por lo que no hay marcado para analizar.\n",
        "*   No hay errores tipográficos o de ortografía evidentes.\n",
        "*   Hay puntuación como comas, apótofresm conillas, signos de interogación y más.\n",
        "*   Hay descripciones con guión como *armour-like*.\n",
        "*   Se usa mucho el guión (-) para continuar oraciones (¿tal vez reemplazarlo con comas?)\n",
        "*   Hay nombres (por ejemplo, Sr. Samsa)\n",
        "*   No parece haber números que requieran manipulación (por ejemplo, 1999)\n",
        "*   Hay marcadores de sección (por ejemplo, II, III)."
      ],
      "metadata": {
        "id": "Wq7RIXUNWrpc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Tokenización manual\n",
        "\n",
        "Las herramientas como las expresiones regulares y la división de cadenas son las principales ala hora de trabajar manualmente el texto."
      ],
      "metadata": {
        "id": "ZuVApscpY_u1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1. Cargar datos\n",
        "\n",
        "Carguemos los datos de texto para qu epodamos trabajar con ellos."
      ],
      "metadata": {
        "id": "yh0dJknDZNTZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "grFkuyGnMgB_"
      },
      "outputs": [],
      "source": [
        "filename = '/content/pg5200.txt'\n",
        "file = open(filename, mode='rt')\n",
        "text = file.read()\n",
        "file.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2. Dividir por espacios en blanco\n",
        "\n",
        "Dividir el documento por espacios en blanco, incluidos \" \"(espacio), nuevas líneas, tabulaciones y más lo realizamos muy facilmente con la función slit() en la cadena cargada.\n",
        "\n",
        "Ejecutar el ejemplo divide el documento en una larga lista de palabras e imprime las primeras 100 para que las revisemos."
      ],
      "metadata": {
        "id": "da40-Tbza0ZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = text.split()\n",
        "print(words[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjkL2bTUaR8A",
        "outputId": "55a69e5b-f558-4cfc-d5cb-d8971d3c15b6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\ufeffOne', 'morning,', 'when', 'Gregor', 'Samsa', 'woke', 'from', 'troubled', 'dreams,', 'he', 'found', 'himself', 'transformed', 'in', 'his', 'bed', 'into', 'a', 'horrible', 'vermin.', 'He', 'lay', 'on', 'his', 'armour-like', 'back,', 'and', 'if', 'he', 'lifted', 'his', 'head', 'a', 'little', 'he', 'could', 'see', 'his', 'brown', 'belly,', 'slightly', 'domed', 'and', 'divided', 'by', 'arches', 'into', 'stiff', 'sections.', 'The', 'bedding', 'was', 'hardly', 'able', 'to', 'cover', 'it', 'and', 'seemed', 'ready', 'to', 'slide', 'off', 'any', 'moment.', 'His', 'many', 'legs,', 'pitifully', 'thin', 'compared', 'with', 'the', 'size', 'of', 'the', 'rest', 'of', 'him,', 'waved', 'about', 'helplessly', 'as', 'he', 'looked.', '“What’s', 'happened', 'to', 'me?”', 'he', 'thought.', 'It', 'wasn’t', 'a', 'dream.', 'His', 'room,', 'a', 'proper', 'human']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3. Seleccionar palabras\n",
        "\n",
        "Otro enfoque podría ser usar el modelo regex de expresiones regulares (re) y dividir el documento en palabras seleccionando cadenas de caracteres alfanuméricos (az, AZ, 0-9 y '')."
      ],
      "metadata": {
        "id": "p8rmTKPgcOHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "words = re.split(r'\\W+', text)\n",
        "print(words[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjwO_771brY7",
        "outputId": "97ef6f5a-cc4a-4296-8140-6d69b76d9894"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', 'One', 'morning', 'when', 'Gregor', 'Samsa', 'woke', 'from', 'troubled', 'dreams', 'he', 'found', 'himself', 'transformed', 'in', 'his', 'bed', 'into', 'a', 'horrible', 'vermin', 'He', 'lay', 'on', 'his', 'armour', 'like', 'back', 'and', 'if', 'he', 'lifted', 'his', 'head', 'a', 'little', 'he', 'could', 'see', 'his', 'brown', 'belly', 'slightly', 'domed', 'and', 'divided', 'by', 'arches', 'into', 'stiff', 'sections', 'The', 'bedding', 'was', 'hardly', 'able', 'to', 'cover', 'it', 'and', 'seemed', 'ready', 'to', 'slide', 'off', 'any', 'moment', 'His', 'many', 'legs', 'pitifully', 'thin', 'compared', 'with', 'the', 'size', 'of', 'the', 'rest', 'of', 'him', 'waved', 'about', 'helplessly', 'as', 'he', 'looked', 'What', 's', 'happened', 'to', 'me', 'he', 'thought', 'It', 'wasn', 't', 'a', 'dream', 'His']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.4. Dividir por espacios en blanco y quitar puntuación\n",
        "\n",
        "Es posible que queramos las palabras, pero sin la puntuación como las comas y las comillas. También queremos mantener las contracciones juntas.\n",
        "\n",
        "Python proporciona una constante lamada String.punctuation que proporciona una excelente lista de caracteres de puntuación. Por ejemplo:"
      ],
      "metadata": {
        "id": "WkfuWE21dIIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "print(string.punctuation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-S3x6vOc4DS",
        "outputId": "3f13a4e7-5507-484d-8f8e-4ec605e8953c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos usar expresiones regulares para seleccionar los caracteres de puntuación y usar la función sub() para reemplazarlos con nada."
      ],
      "metadata": {
        "id": "1kwVb1F6d1oO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "words = text.split()\n",
        "re_punc = re.compile('[%s]' % re.escape(string.punctuation)) # Identifica los signos de puntucación\n",
        "\n",
        "stripped = [re_punc.sub('', w) for w in words] # Elimina cada palabra los signos de puntuación definido en re_punc\n",
        "\n",
        "print(words[:100])\n",
        "print(stripped[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sikg1q51d0Da",
        "outputId": "0617a7ab-4aa4-4024-f137-d22f48c88c5e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\ufeffOne', 'morning,', 'when', 'Gregor', 'Samsa', 'woke', 'from', 'troubled', 'dreams,', 'he', 'found', 'himself', 'transformed', 'in', 'his', 'bed', 'into', 'a', 'horrible', 'vermin.', 'He', 'lay', 'on', 'his', 'armour-like', 'back,', 'and', 'if', 'he', 'lifted', 'his', 'head', 'a', 'little', 'he', 'could', 'see', 'his', 'brown', 'belly,', 'slightly', 'domed', 'and', 'divided', 'by', 'arches', 'into', 'stiff', 'sections.', 'The', 'bedding', 'was', 'hardly', 'able', 'to', 'cover', 'it', 'and', 'seemed', 'ready', 'to', 'slide', 'off', 'any', 'moment.', 'His', 'many', 'legs,', 'pitifully', 'thin', 'compared', 'with', 'the', 'size', 'of', 'the', 'rest', 'of', 'him,', 'waved', 'about', 'helplessly', 'as', 'he', 'looked.', '“What’s', 'happened', 'to', 'me?”', 'he', 'thought.', 'It', 'wasn’t', 'a', 'dream.', 'His', 'room,', 'a', 'proper', 'human']\n",
            "['\\ufeffOne', 'morning', 'when', 'Gregor', 'Samsa', 'woke', 'from', 'troubled', 'dreams', 'he', 'found', 'himself', 'transformed', 'in', 'his', 'bed', 'into', 'a', 'horrible', 'vermin', 'He', 'lay', 'on', 'his', 'armourlike', 'back', 'and', 'if', 'he', 'lifted', 'his', 'head', 'a', 'little', 'he', 'could', 'see', 'his', 'brown', 'belly', 'slightly', 'domed', 'and', 'divided', 'by', 'arches', 'into', 'stiff', 'sections', 'The', 'bedding', 'was', 'hardly', 'able', 'to', 'cover', 'it', 'and', 'seemed', 'ready', 'to', 'slide', 'off', 'any', 'moment', 'His', 'many', 'legs', 'pitifully', 'thin', 'compared', 'with', 'the', 'size', 'of', 'the', 'rest', 'of', 'him', 'waved', 'about', 'helplessly', 'as', 'he', 'looked', '“What’s', 'happened', 'to', 'me”', 'he', 'thought', 'It', 'wasn’t', 'a', 'dream', 'His', 'room', 'a', 'proper', 'human']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A veces, los datos de texto prueden contener caracteres no imprimibles, Pormos usar un enfoque similar para filtrar todos los caracteres no imprimibles seleccionando el inverso de la constante String.printable. Por ejemplo:"
      ],
      "metadata": {
        "id": "If8esxPih5cw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = text.split()\n",
        "re_print = re.compile('[%s]' % re.escape(string.printable)) # Identifica los caracteres imprimibles\n",
        "\n",
        "results = [re_print.sub('', w) for w in words]\n",
        "print(results[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdfiwLuIhYJs",
        "outputId": "6b5e4cef-a04a-4d11-96ea-fc4102017c13"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\ufeff', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '“’', '', '', '”', '', '', '', '’', '', '', '', '', '', '', '']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.5. Caso de normalización\n",
        "\n",
        "Es común convertir todas las palabras a un caso.\n",
        "\n",
        "Podemos convertir todas las palabras a minúsculas llamando a la función lower() en cada palabra."
      ],
      "metadata": {
        "id": "GS5m72FOgYBy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = text.split()\n",
        "words = [word.lower() for word in words]\n",
        "print(words[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtPTTtTteSy5",
        "outputId": "fde97236-49fe-4205-8643-dc05fd713a71"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\ufeffone', 'morning,', 'when', 'gregor', 'samsa', 'woke', 'from', 'troubled', 'dreams,', 'he', 'found', 'himself', 'transformed', 'in', 'his', 'bed', 'into', 'a', 'horrible', 'vermin.', 'he', 'lay', 'on', 'his', 'armour-like', 'back,', 'and', 'if', 'he', 'lifted', 'his', 'head', 'a', 'little', 'he', 'could', 'see', 'his', 'brown', 'belly,', 'slightly', 'domed', 'and', 'divided', 'by', 'arches', 'into', 'stiff', 'sections.', 'the', 'bedding', 'was', 'hardly', 'able', 'to', 'cover', 'it', 'and', 'seemed', 'ready', 'to', 'slide', 'off', 'any', 'moment.', 'his', 'many', 'legs,', 'pitifully', 'thin', 'compared', 'with', 'the', 'size', 'of', 'the', 'rest', 'of', 'him,', 'waved', 'about', 'helplessly', 'as', 'he', 'looked.', '“what’s', 'happened', 'to', 'me?”', 'he', 'thought.', 'it', 'wasn’t', 'a', 'dream.', 'his', 'room,', 'a', 'proper', 'human']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xi__DW4ThIHk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}